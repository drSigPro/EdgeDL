{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref https://github.com/wanglouis49/pytorch-weights_pruning/tree/master\n",
    "#Ref https://pytorch.org/tutorials/intermediate/pruning_tutorial.html\n",
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    model_size = os.path.getsize(\"temp.p\")/1e3\n",
    "    print('Size (KB):', model_size)\n",
    "    os.remove('temp.p')\n",
    "    return model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.mask_flag = False\n",
    "    \n",
    "    def set_mask(self, mask):\n",
    "        self.mask = Variable(mask, requires_grad=False, volatile=False)\n",
    "        self.weight.data = self.weight.data*self.mask.data\n",
    "        self.mask_flag = True\n",
    "    \n",
    "    def get_mask(self):\n",
    "        print(self.mask_flag)\n",
    "        return self.mask\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mask_flag == True:\n",
    "            weight = self.weight*self.mask\n",
    "            return F.linear(x, weight, self.bias)\n",
    "        else:\n",
    "            return F.linear(x, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(MaskedConv2d, self).__init__(in_channels, out_channels, \n",
    "            kernel_size, stride, padding, dilation, groups, bias)\n",
    "        self.mask_flag = False\n",
    "    \n",
    "    def set_mask(self, mask):\n",
    "        self.mask = Variable(mask, requires_grad=False, volatile=False)\n",
    "        self.weight.data = self.weight.data*self.mask.data\n",
    "        self.mask_flag = True\n",
    "    \n",
    "    def get_mask(self):\n",
    "        print(self.mask_flag)\n",
    "        return self.mask\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.mask_flag == True:\n",
    "            weight = self.weight*self.mask\n",
    "            return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "        else:\n",
    "            return F.conv2d(x, self.weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_one_filter(model, masks):\n",
    "    '''\n",
    "    Pruning one least ``important'' feature map by the scaled l2norm of \n",
    "    kernel weights\n",
    "    arXiv:1611.06440\n",
    "    '''\n",
    "    NO_MASKS = False\n",
    "    # construct masks if there is not yet\n",
    "    if not masks:\n",
    "        masks = []\n",
    "        NO_MASKS = True\n",
    "\n",
    "    values = []\n",
    "    for p in model.parameters():\n",
    "\n",
    "        if len(p.data.size()) == 4: # nasty way of selecting conv layer\n",
    "            p_np = p.data.cpu().numpy()\n",
    "\n",
    "            # construct masks if there is not\n",
    "            if NO_MASKS:\n",
    "                masks.append(np.ones(p_np.shape).astype('float32'))\n",
    "\n",
    "            # find the scaled l2 norm for each filter this layer\n",
    "            value_this_layer = np.square(p_np).sum(axis=1).sum(axis=1)\\\n",
    "                .sum(axis=1)/(p_np.shape[1]*p_np.shape[2]*p_np.shape[3])\n",
    "            # normalization (important)\n",
    "            value_this_layer = value_this_layer / \\\n",
    "                np.sqrt(np.square(value_this_layer).sum())\n",
    "            min_value, min_ind = arg_nonzero_min(list(value_this_layer))\n",
    "            values.append([min_value, min_ind])\n",
    "\n",
    "    assert len(masks) == len(values), \"something wrong here\"\n",
    "\n",
    "    values = np.array(values)\n",
    "\n",
    "    # set mask corresponding to the filter to prune\n",
    "    to_prune_layer_ind = np.argmin(values[:, 0])\n",
    "    to_prune_filter_ind = int(values[to_prune_layer_ind, 1])\n",
    "    masks[to_prune_layer_ind][to_prune_filter_ind] = 0.\n",
    "\n",
    "    print('Prune filter #{} in layer #{}'.format(\n",
    "        to_prune_filter_ind, \n",
    "        to_prune_layer_ind))\n",
    "\n",
    "    return masks\n",
    "\n",
    "\n",
    "def filter_prune(model, pruning_perc):\n",
    "    '''\n",
    "    Prune filters one by one until reach pruning_perc\n",
    "    (not iterative pruning)\n",
    "    '''\n",
    "    masks = []\n",
    "    current_pruning_perc = 0.\n",
    "\n",
    "    while current_pruning_perc < pruning_perc:\n",
    "        masks = prune_one_filter(model, masks)\n",
    "        model.set_masks(masks)\n",
    "        current_pruning_perc = prune_rate(model, verbose=False)\n",
    "        print('{:.2f} pruned'.format(current_pruning_perc))\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_rate(model, verbose=True):\n",
    "    \"\"\"\n",
    "    Print out prune rate for each layer and the whole network\n",
    "    \"\"\"\n",
    "    total_nb_param = 0\n",
    "    nb_zero_param = 0\n",
    "\n",
    "    layer_id = 0\n",
    "\n",
    "    for parameter in model.parameters():\n",
    "\n",
    "        param_this_layer = 1\n",
    "        for dim in parameter.data.size():\n",
    "            param_this_layer *= dim\n",
    "        total_nb_param += param_this_layer\n",
    "\n",
    "        # only pruning linear and conv layers\n",
    "        if len(parameter.data.size()) != 1:\n",
    "            layer_id += 1\n",
    "            zero_param_this_layer = \\\n",
    "                np.count_nonzero(parameter.cpu().data.numpy()==0)\n",
    "            nb_zero_param += zero_param_this_layer\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Layer {} | {} layer | {:.2f}% parameters pruned\" \\\n",
    "                    .format(\n",
    "                        layer_id,\n",
    "                        'Conv' if len(parameter.data.size()) == 4 \\\n",
    "                            else 'Linear',\n",
    "                        100.*zero_param_this_layer/param_this_layer,\n",
    "                        ))\n",
    "    pruning_perc = 100.*nb_zero_param/total_nb_param\n",
    "    if verbose:\n",
    "        print(\"Final pruning rate: {:.2f}%\".format(pruning_perc))\n",
    "    return pruning_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_nonzero_min(a):\n",
    "    \"\"\"\n",
    "    nonzero argmin of a non-negative array\n",
    "    \"\"\"\n",
    "\n",
    "    if not a:\n",
    "        return\n",
    "\n",
    "    min_ix, min_v = None, None\n",
    "    # find the starting value (should be nonzero)\n",
    "    for i, e in enumerate(a):\n",
    "        if e != 0:\n",
    "            min_ix = i\n",
    "            min_v = e\n",
    "    if not min_ix:\n",
    "        print('Warning: all zero')\n",
    "        return np.inf, np.inf\n",
    "\n",
    "    # search for the smallest nonzero\n",
    "    for i, e in enumerate(a):\n",
    "         if e < min_v and e != 0:\n",
    "            min_v = e\n",
    "            min_ix = i\n",
    "\n",
    "    return min_v, min_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the non-pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 =nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(7*7*64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        out = self.maxpool2(self.relu2(self.conv2(out)))\n",
    "        out = self.relu3(self.conv3(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and setting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epochs=5):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            if (i+1) % 500 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [500/6000], Loss: 0.0115\n",
      "Epoch [1/1], Step [1000/6000], Loss: 0.0255\n",
      "Epoch [1/1], Step [1500/6000], Loss: 0.0517\n",
      "Epoch [1/1], Step [2000/6000], Loss: 0.0784\n",
      "Epoch [1/1], Step [2500/6000], Loss: 0.0009\n",
      "Epoch [1/1], Step [3000/6000], Loss: 0.0062\n",
      "Epoch [1/1], Step [3500/6000], Loss: 0.0125\n",
      "Epoch [1/1], Step [4000/6000], Loss: 0.0015\n",
      "Epoch [1/1], Step [4500/6000], Loss: 0.0003\n",
      "Epoch [1/1], Step [5000/6000], Loss: 0.0885\n",
      "Epoch [1/1], Step [5500/6000], Loss: 0.0506\n",
      "Epoch [1/1], Step [6000/6000], Loss: 0.0358\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, model, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for idx, i in enumerate(outputs):\n",
    "                if torch.argmax(i) == labels[idx]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "                \n",
    "    print(f'Accuracy: {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "test(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = MaskedConv2d(1, 32, kernel_size=3, padding=1, stride=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = MaskedConv2d(32, 64, kernel_size=3, padding=1, stride=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = MaskedConv2d(64, 64, kernel_size=3, padding=1, stride=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(7*7*64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        out = self.maxpool2(self.relu2(self.conv2(out)))\n",
    "        out = self.relu3(self.conv3(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear1(out)\n",
    "        return out\n",
    "\n",
    "    def set_masks(self, masks):\n",
    "        # Should be a less manual way to set masks\n",
    "        # Leave it for the future\n",
    "        self.conv1.set_mask(torch.from_numpy(masks[0]))\n",
    "        self.conv2.set_mask(torch.from_numpy(masks[1]))\n",
    "        self.conv3.set_mask(torch.from_numpy(masks[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "newmodel = ConvNet().to(device)\n",
    "newmodel.load_state_dict(torch.load('CNN.pt'))\n",
    "print('Loaded model from disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "test(test_loader,newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune filter #1 in layer #1\n",
      "0.99 pruned\n",
      "Prune filter #61 in layer #1\n",
      "1.32 pruned\n",
      "Prune filter #11 in layer #1\n",
      "1.65 pruned\n",
      "Prune filter #59 in layer #1\n",
      "1.98 pruned\n",
      "Prune filter #16 in layer #1\n",
      "2.31 pruned\n",
      "Prune filter #26 in layer #1\n",
      "2.64 pruned\n",
      "Prune filter #23 in layer #0\n",
      "2.66 pruned\n",
      "Prune filter #42 in layer #1\n",
      "2.99 pruned\n",
      "Prune filter #31 in layer #2\n",
      "3.65 pruned\n",
      "Prune filter #29 in layer #0\n",
      "3.66 pruned\n",
      "Prune filter #14 in layer #2\n",
      "4.32 pruned\n",
      "Prune filter #52 in layer #1\n",
      "4.65 pruned\n",
      "Prune filter #37 in layer #1\n",
      "4.98 pruned\n",
      "Prune filter #15 in layer #2\n",
      "5.64 pruned\n",
      "Prune filter #55 in layer #1\n",
      "5.97 pruned\n",
      "Prune filter #56 in layer #2\n",
      "6.63 pruned\n",
      "Prune filter #15 in layer #0\n",
      "6.64 pruned\n",
      "Prune filter #24 in layer #2\n",
      "7.30 pruned\n",
      "Prune filter #13 in layer #0\n",
      "7.31 pruned\n",
      "Prune filter #32 in layer #2\n",
      "7.98 pruned\n",
      "Prune filter #12 in layer #2\n",
      "8.64 pruned\n",
      "Prune filter #7 in layer #1\n",
      "8.97 pruned\n",
      "Prune filter #34 in layer #2\n",
      "9.63 pruned\n",
      "Prune filter #63 in layer #1\n",
      "9.96 pruned\n",
      "Prune filter #32 in layer #1\n",
      "10.29 pruned\n",
      "Prune filter #29 in layer #2\n",
      "10.95 pruned\n",
      "Prune filter #5 in layer #0\n",
      "10.96 pruned\n",
      "Prune filter #55 in layer #2\n",
      "11.62 pruned\n",
      "Prune filter #20 in layer #2\n",
      "12.28 pruned\n",
      "Prune filter #5 in layer #2\n",
      "12.95 pruned\n",
      "Prune filter #22 in layer #1\n",
      "13.28 pruned\n",
      "Prune filter #4 in layer #2\n",
      "13.94 pruned\n",
      "Prune filter #39 in layer #1\n",
      "14.27 pruned\n",
      "Prune filter #7 in layer #0\n",
      "14.28 pruned\n",
      "Prune filter #43 in layer #1\n",
      "14.61 pruned\n",
      "Prune filter #57 in layer #2\n",
      "15.27 pruned\n",
      "Prune filter #52 in layer #2\n",
      "15.93 pruned\n",
      "Prune filter #28 in layer #1\n",
      "16.26 pruned\n",
      "Prune filter #9 in layer #2\n",
      "16.92 pruned\n",
      "Prune filter #10 in layer #1\n",
      "17.25 pruned\n",
      "Prune filter #24 in layer #1\n",
      "17.58 pruned\n",
      "Prune filter #59 in layer #2\n",
      "18.25 pruned\n",
      "Prune filter #20 in layer #0\n",
      "18.26 pruned\n",
      "Prune filter #57 in layer #1\n",
      "18.59 pruned\n",
      "Prune filter #7 in layer #2\n",
      "19.25 pruned\n",
      "Prune filter #17 in layer #1\n",
      "19.58 pruned\n",
      "Prune filter #38 in layer #2\n",
      "20.24 pruned\n",
      "Prune filter #46 in layer #1\n",
      "20.57 pruned\n",
      "Prune filter #26 in layer #0\n",
      "20.58 pruned\n",
      "Prune filter #44 in layer #2\n",
      "21.24 pruned\n",
      "Prune filter #56 in layer #1\n",
      "21.57 pruned\n",
      "Prune filter #3 in layer #2\n",
      "22.23 pruned\n",
      "Prune filter #41 in layer #1\n",
      "22.56 pruned\n",
      "Prune filter #51 in layer #1\n",
      "22.89 pruned\n",
      "Prune filter #18 in layer #2\n",
      "23.56 pruned\n",
      "Prune filter #29 in layer #1\n",
      "23.89 pruned\n",
      "Prune filter #54 in layer #2\n",
      "24.55 pruned\n",
      "Prune filter #48 in layer #1\n",
      "24.88 pruned\n",
      "Prune filter #21 in layer #1\n",
      "25.21 pruned\n",
      "Prune filter #0 in layer #2\n",
      "25.87 pruned\n",
      "Prune filter #2 in layer #0\n",
      "25.88 pruned\n",
      "Prune filter #13 in layer #2\n",
      "26.54 pruned\n",
      "Prune filter #13 in layer #1\n",
      "26.87 pruned\n",
      "Prune filter #21 in layer #2\n",
      "27.53 pruned\n",
      "Prune filter #60 in layer #1\n",
      "27.86 pruned\n",
      "Prune filter #36 in layer #2\n",
      "28.52 pruned\n",
      "Prune filter #5 in layer #1\n",
      "28.86 pruned\n",
      "Prune filter #42 in layer #2\n",
      "29.52 pruned\n",
      "Prune filter #8 in layer #1\n",
      "29.85 pruned\n",
      "Prune filter #17 in layer #2\n",
      "30.51 pruned\n",
      "Prune filter #10 in layer #0\n",
      "30.52 pruned\n",
      "Prune filter #51 in layer #2\n",
      "31.18 pruned\n",
      "Prune filter #4 in layer #1\n",
      "31.51 pruned\n",
      "Prune filter #48 in layer #2\n",
      "32.17 pruned\n",
      "Prune filter #23 in layer #1\n",
      "32.50 pruned\n",
      "Prune filter #37 in layer #2\n",
      "33.16 pruned\n",
      "Prune filter #3 in layer #1\n",
      "33.49 pruned\n",
      "Prune filter #10 in layer #2\n",
      "34.16 pruned\n",
      "Prune filter #18 in layer #1\n",
      "34.49 pruned\n",
      "Prune filter #61 in layer #2\n",
      "35.15 pruned\n",
      "Prune filter #9 in layer #1\n",
      "35.48 pruned\n",
      "Prune filter #14 in layer #0\n",
      "35.49 pruned\n",
      "Prune filter #39 in layer #2\n",
      "36.15 pruned\n",
      "Prune filter #38 in layer #1\n",
      "36.48 pruned\n",
      "Prune filter #8 in layer #2\n",
      "37.14 pruned\n",
      "Prune filter #19 in layer #1\n",
      "37.47 pruned\n",
      "Prune filter #49 in layer #1\n",
      "37.80 pruned\n",
      "Prune filter #53 in layer #2\n",
      "38.46 pruned\n",
      "Prune filter #0 in layer #0\n",
      "38.47 pruned\n",
      "Prune filter #2 in layer #2\n",
      "39.13 pruned\n",
      "Prune filter #53 in layer #1\n",
      "39.47 pruned\n",
      "Prune filter #28 in layer #2\n",
      "40.13 pruned\n",
      "Prune filter #44 in layer #1\n",
      "40.46 pruned\n",
      "Prune filter #31 in layer #0\n",
      "40.47 pruned\n",
      "Prune filter #49 in layer #2\n",
      "41.13 pruned\n",
      "Prune filter #36 in layer #1\n",
      "41.46 pruned\n",
      "Prune filter #19 in layer #2\n",
      "42.12 pruned\n",
      "Prune filter #26 in layer #2\n",
      "42.78 pruned\n",
      "Prune filter #34 in layer #1\n",
      "43.11 pruned\n",
      "Prune filter #3 in layer #0\n",
      "43.12 pruned\n",
      "Prune filter #11 in layer #2\n",
      "43.78 pruned\n",
      "Prune filter #25 in layer #1\n",
      "44.11 pruned\n",
      "Prune filter #12 in layer #0\n",
      "44.12 pruned\n",
      "Prune filter #60 in layer #2\n",
      "44.79 pruned\n",
      "Prune filter #8 in layer #0\n",
      "44.80 pruned\n",
      "Prune filter #45 in layer #2\n",
      "45.46 pruned\n",
      "Prune filter #62 in layer #1\n",
      "45.79 pruned\n",
      "Prune filter #33 in layer #2\n",
      "46.45 pruned\n",
      "Prune filter #1 in layer #0\n",
      "46.46 pruned\n",
      "Prune filter #0 in layer #1\n",
      "46.79 pruned\n",
      "Prune filter #23 in layer #2\n",
      "47.45 pruned\n",
      "Prune filter #20 in layer #1\n",
      "47.78 pruned\n",
      "Prune filter #16 in layer #2\n",
      "48.44 pruned\n",
      "Prune filter #27 in layer #0\n",
      "48.45 pruned\n",
      "Prune filter #27 in layer #1\n",
      "48.78 pruned\n",
      "Prune filter #46 in layer #2\n",
      "49.45 pruned\n",
      "Prune filter #24 in layer #0\n",
      "49.46 pruned\n",
      "Prune filter #2 in layer #1\n",
      "49.79 pruned\n",
      "Prune filter #25 in layer #2\n",
      "50.45 pruned\n",
      "--- 50.0% parameters pruned ---\n",
      "Accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "# prune the weights\n",
    "pruning_perc =  50.\n",
    "masks = filter_prune(newmodel, pruning_perc)\n",
    "newmodel.set_masks(masks)\n",
    "print(\"--- {}% parameters pruned ---\".format(pruning_perc))\n",
    "test(test_loader, newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [500/6000], Loss: 0.0629\n",
      "Epoch [1/1], Step [1000/6000], Loss: 0.0038\n",
      "Epoch [1/1], Step [1500/6000], Loss: 0.0302\n",
      "Epoch [1/1], Step [2000/6000], Loss: 0.1966\n",
      "Epoch [1/1], Step [2500/6000], Loss: 0.0041\n",
      "Epoch [1/1], Step [3000/6000], Loss: 0.0045\n",
      "Epoch [1/1], Step [3500/6000], Loss: 0.1324\n",
      "Epoch [1/1], Step [4000/6000], Loss: 0.0145\n",
      "Epoch [1/1], Step [4500/6000], Loss: 0.0699\n",
      "Epoch [1/1], Step [5000/6000], Loss: 0.1469\n",
      "Epoch [1/1], Step [5500/6000], Loss: 0.0438\n",
      "Epoch [1/1], Step [6000/6000], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, newmodel, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After retraining ---\n",
      "Accuracy: 0.988\n",
      "Layer 1 | Conv layer | 59.38% parameters pruned\n",
      "Layer 2 | Conv layer | 81.25% parameters pruned\n",
      "Layer 3 | Conv layer | 78.12% parameters pruned\n",
      "Layer 4 | Linear layer | 0.00% parameters pruned\n",
      "Final pruning rate: 50.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.44768923479578"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy and nonzeros weights in each layer\n",
    "print(\"--- After retraining ---\")\n",
    "test(test_loader,newmodel)\n",
    "prune_rate(newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the entire model\n",
    "torch.save(model.state_dict(), 'CNN_Pruned.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
